{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahrish11/StyleGAN2-ADA_Goldfish-Training/blob/main/StyleGAN2_ADA_Goldfish_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk2xlFCqrbi4",
        "outputId": "f7ac6ef0-a8eb-48aa-f401-321f93e2a682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.14\n",
            "Mon Oct 10 06:36:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAWtEieq5VG3",
        "outputId": "565a395a-7092-491e-f3a8-a854c8dfbf16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  COLAB=True\n",
        "  print(\"Note: using Google CoLab\")\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  print(\"Note: not using Google CoLab\")\n",
        "  COLAB=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPClaHAm6Y0G"
      },
      "source": [
        "###Installing NVIDIA StyleGAN2-ADA repository "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1Y-JlK46gKn",
        "outputId": "5839b64b-55d6-4f6e-cb4e-580bc3a6d12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 1.12 MiB | 14.53 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.6 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1\n",
            "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.1 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1 torchvision-0.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Collecting pyspng\n",
            "  Downloading pyspng-0.1.0-cp37-cp37m-manylinux2010_x86_64.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 31.8 MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n",
            "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng) (1.21.6)\n",
            "Installing collected packages: pyspng, ninja, imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.10.2.4 pyspng-0.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==1.15.0\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 20.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.49.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.21.6)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.17.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (2.0.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=14040bda532072e57c203b4bc11f163e28a108949cc3218d3ac56f86e465d89e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220929150707 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220929150707 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "!pip install torch==1.8.1 torchvision==0.9.1\n",
        "!pip install ninja click requests tqdm pyspng imageio-ffmpeg==0.4.3 \n",
        "!pip install tensorflow-gpu==1.15.0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4irwLZD681A"
      },
      "source": [
        "### Locating your folder for imageset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoU_kpTm7BST",
        "outputId": "5b402f6a-3e0b-44ce-fc50-8a7e98abaae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00MBU1PJRPVD.jpg  8XB6V3M26SQM.jpg  IEC8U2HAYV92.jpg  R2WU13C5HHJV.jpg\n",
            "0399DADI9H61.jpg  8ZF1M60BR4SO.jpg  IGBV2MLLDCY4.jpg  R4TO6SCADUHO.jpg\n",
            "03UJQXPI2VCN.jpg  8ZICH5W7H4D6.jpg  IGN84NA27YCG.jpg  R5C5GWC7GKHB.jpg\n",
            "045KP4KGZBSN.jpg  91ECXAR6I22F.jpg  IHQY5U967FDZ.jpg  R5QVVBTTZFIO.jpg\n",
            "06OCLMQQM2TK.jpg  92HGU67BX86D.jpg  IHSAYM5AN43L.jpg  R76PONNYZUDL.jpg\n",
            "06SPLITBK3UB.jpg  92MCBG10VGAV.jpg  IJR8GM5GARWS.jpg  R7WTT3Z0IN15.jpg\n",
            "07SJEUO8KPJT.jpg  93R2DOYQAOH0.jpg  IJX4U1MX25Q7.jpg  R8HIUKVR08K4.jpg\n",
            "087E1YQXWG38.jpg  948OSJKHA4Q2.jpg  IJYHE7DWSN9L.jpg  R8SXCRE0DYSR.jpg\n",
            "09MM9HZR540E.jpg  94E72B5X9JAX.jpg  IK0J2NHLZNQY.jpg  RA6WUMUURIT1.jpg\n",
            "0A9GXCMHU3SZ.jpg  9581LNKXJ5MO.jpg  IKY9C729KPVG.jpg  RA96YB7RA3BP.jpg\n",
            "0DHKK9M67YR9.jpg  96DGJMSAS0QZ.jpg  ILBRTPCNOYUS.jpg  RABKAP5KI0W1.jpg\n",
            "0DIUNHB04K0U.jpg  97IW2MOS8RZB.jpg  ILBWA0U6WY9R.jpg  RB2U3LXV6E88.jpg\n",
            "0FA73W83Z2AI.jpg  980SDKJZMJV4.jpg  IM5KSOGE1KF4.jpg  RBV06Y0XS6NA.jpg\n",
            "0GDKVPTAO499.jpg  9810VIWMFF0K.jpg  IPRP5D20744W.jpg  RCKPSBND2B7I.jpg\n",
            "0GVNEOOSGD2R.jpg  98187HTBQLIO.jpg  IPUQGX8YV3AC.jpg  RD3B6T87420V.jpg\n",
            "0HRBMPQAXTQS.jpg  99UYCV8L5B4T.jpg  IQDWAZOIGMCL.jpg  RFNPOR5ZNEEL.jpg\n",
            "0LZ97X3PD55H.jpg  9AAANSYQR4V4.jpg  IS6MF8QVDQ5Q.jpg  RG0WIW0KQU8R.jpg\n",
            "0M8ODVFB8DYH.jpg  9AABB6JNJWS6.jpg  ISH8WR95EG36.jpg  RH4DEGQQRDL5.jpg\n",
            "0OCWIRZH8KSG.jpg  9C4ZLJNFXFWZ.jpg  ISPQMDRQ1AWQ.jpg  RIDDUJOSB0JN.jpg\n",
            "0OO9N8FINAU2.jpg  9DBAXJISWKTW.jpg  ISUAM7IKUHT6.jpg  RJGN2TZT22RN.jpg\n",
            "0P5SMQ786KOR.jpg  9F4DY16C8N7L.jpg  IV2EGF5A6X21.jpg  RMPJ1UBK5OMO.jpg\n",
            "0PEUW553ZBSP.jpg  9FNZCU4DRZQ5.jpg  IVC8ER53HGO6.jpg  RNQJ9L8P8CC3.jpg\n",
            "0PK5306JJV51.jpg  9FT8T03APIV4.jpg  IVUOG6FR3XEP.jpg  ROIRAFAHK4X1.jpg\n",
            "0QTDVMGPU0S8.jpg  9G4WX7MDWKMX.jpg  IWSN8GNREZTJ.jpg  ROXTHFNMW60I.jpg\n",
            "0RQ5MU6J9LT2.jpg  9GOO3N2MPP35.jpg  IYNENZ7U4ZCY.jpg  RPCLFB5JYLE7.jpg\n",
            "0RY2YQW2KN30.jpg  9GV6MYVT5QBO.jpg  J09B9KDTIYBZ.jpg  RPWUCIPPWAKY.jpg\n",
            "0SWGXI2AIRMU.jpg  9HDVCQNIUFOK.jpg  J2W5MMTMM7TH.jpg  RQG81KZX028F.jpg\n",
            "0UGHW7G11PHN.jpg  9HGJDABP7MI0.jpg  J6M2LL0Z2C8Y.jpg  RSFW7GGLTOHY.jpg\n",
            "0USXE91EHA10.jpg  9HJO2L8YU2Z7.jpg  J9SEQION4NEB.jpg  RU73KBL8IA4L.jpg\n",
            "0WTNCJDNZ4M8.jpg  9HO0AV3XJD80.jpg  J9W6UK4UXZ8N.jpg  RU8K4YX4Z6SX.jpg\n",
            "0XP648XYQ260.jpg  9IVQ3HX3XN2H.jpg  JASA2K7NADWR.jpg  RUL7CFY1AFDK.jpg\n",
            "0XV91NHLTZE0.jpg  9J1NR1XPVAT9.jpg  JDE8QBYG7FPY.jpg  RV5SC1XNR60U.jpg\n",
            "0YPDB7IMB4JO.jpg  9JXQXYYBST85.jpg  JFVZSZJO9RI1.jpg  RW8AMEZZTTEW.jpg\n",
            "0Z6E46A5428F.jpg  9K9PPTCHVRD1.jpg  JHBB1NPO16M9.jpg  RX1PFFCHQHF3.jpg\n",
            "0ZGFC4EYU1FJ.jpg  9LVBWA55OXJI.jpg  JHPL9WXWIJEU.jpg  RX9HI9ANV7TE.jpg\n",
            "10GS421HYL5W.jpg  9LWTDVIVE38A.jpg  JHPRUM2L8F97.jpg  RXERVSGPH59M.jpg\n",
            "11E4WLZYVL7Z.jpg  9Q54ZO09ZLRK.jpg  JJ3TXJYMFOXT.jpg  RXFD61Z8V28L.jpg\n",
            "126RVXGOIM1N.jpg  9QF6H449SRQC.jpg  JJIH8SP7EFP2.jpg  RZL2839EZIDD.jpg\n",
            "12Y62S1GEZLC.jpg  9RRNPTUTC68J.jpg  JK8K2EYOQV07.jpg  RZNU5JCOMP5K.jpg\n",
            "134AW4ELT2VA.jpg  9T0UIT0MQ35A.jpg  JLTU6PN6VMFR.jpg  S0FUT32WEVOS.jpg\n",
            "138AQPDR554V.jpg  9TV0N09OBG4X.jpg  JMBIYEG6R87M.jpg  S199DJOJ55QO.jpg\n",
            "13WWD0J2UBDE.jpg  9UXSADIV9QS0.jpg  JMHQO0JGO25R.jpg  S1JHBA1E1CYK.jpg\n",
            "150Y854VOJZD.jpg  9VH9RCTDOO0G.jpg  JPGSU8BMIOJP.jpg  S2EH9MOLP4BJ.jpg\n",
            "152HHB1C0KZY.jpg  9XBXJA8LG6GH.jpg  JPSDYHHWURW5.jpg  S2WAKJKKXKEZ.jpg\n",
            "172T0H4R9MQZ.jpg  9XRSOBBT38ZY.jpg  JPUS0SAB5D2H.jpg  S2WFN7RRAOLI.jpg\n",
            "17LEKQEOQBKK.jpg  9Y46MXKKOOC0.jpg  JQ5S279JA4QT.jpg  S2ZDZ9ZBKQWQ.jpg\n",
            "17OBBOX5SF8Y.jpg  9Y9T1IHGGWZ9.jpg  JQ8AUL82QST8.jpg  S31RVFZES4W1.jpg\n",
            "17XVZ6N5BC3C.jpg  9Z3BEG4UBRLN.jpg  JQHLNDQM1LTT.jpg  S3NII01VO83S.jpg\n",
            "18FJOYQ1OATI.jpg  9ZSLPBD7IGDO.jpg  JQLUGDP9E4RA.jpg  S5NPEWX94BNB.jpg\n",
            "18GUC488YZEW.jpg  A1YPALQN6CVA.jpg  JQUY1Q5UVZJ7.jpg  S778CMGSP1F4.jpg\n",
            "1A2OSHESU3CI.jpg  A2Z7RKTVOS0U.jpg  JS4DTPE1D380.jpg  S7NCEFRPN546.jpg\n",
            "1A523ZWFZ9CT.jpg  A4AHPD8B3FX3.jpg  JSO1UWJJUMW1.jpg  S8AHDTPE2B3W.jpg\n",
            "1AUMSD2APQKQ.jpg  A610FPLBURC3.jpg  JTMDHSI6DMO5.jpg  S8U7QR52XZJW.jpg\n",
            "1BBKAA1B7I59.jpg  A62SX2WDCDLD.jpg  JUX1GP2E19CB.jpg  SDC7NEI4GE00.jpg\n",
            "1BGUDJH51VR9.jpg  A6DZ0GUMM4MK.jpg  JW4ID49RI98N.jpg  SE9TFED4N7IF.jpg\n",
            "1BKFNV63HC7Q.jpg  A6U0GIP0Y6QO.jpg  JX6IKXTA9PIR.jpg  SFE49N3YZJB0.jpg\n",
            "1C8F4TL7ZDKA.jpg  A79RGVZEYLPO.jpg  JXM7ABA9IYGQ.jpg  SIL62MAH2SOK.jpg\n",
            "1C8I86Z8KSNJ.jpg  A7RIR4408PJG.jpg  JXV8IC1M4D2R.jpg  SJMR3C9PFK2F.jpg\n",
            "1CEY5DM60PFI.jpg  A9PQU2158IG9.jpg  JXWBB9WPGY3P.jpg  SL90UDI8WJSD.jpg\n",
            "1CSUFIA1U6IB.jpg  AAIZAC81M01Z.jpg  JYE2BED1C1LT.jpg  SMAOZI38BD1R.jpg\n",
            "1DO4T17TZQBM.jpg  AB0LPT1872K1.jpg  JZBJNZKCXBZN.jpg  SN2HHQRXDI5P.jpg\n",
            "1HA0GI0EKCSF.jpg  ACVOCSSQ3M48.jpg  JZIY2CLFF9OK.jpg  SOHUBN9TC8JY.jpg\n",
            "1HXQ08XTMRT3.jpg  AE8HDPYBO048.jpg  JZY4REXYIKGY.jpg  SPGNAATK2BMH.jpg\n",
            "1IYM87L89W41.jpg  AESL4PAQEMLT.jpg  K04NXRZ9H6J7.jpg  SPMY2PIQKC6B.jpg\n",
            "1J8WTQCNVCOD.jpg  AFIDNL6ZUK0I.jpg  K2YOG8TADEGP.jpg  SPP0HLXJKMM1.jpg\n",
            "1J9MXO0UDBEX.jpg  AFVDIACNNED2.jpg  K4BLLH7S1ZKB.jpg  SQYH0MIMBZ18.jpg\n",
            "1JSE42TPIYUR.jpg  AFVQ8T0WHQFI.jpg  K5KGC0NIXZQO.jpg  SRRFRFADW7UQ.jpg\n",
            "1MNFC3W3UBDW.jpg  AGRNAE2K28YT.jpg  K60HRUKM99VS.jpg  SRSQT3HNA9BO.jpg\n",
            "1N6A4TK0EHO9.jpg  AHEJXC5QZ7JS.jpg  K71KOXPQPG20.jpg  SVWOUV6JO3WA.jpg\n",
            "1NCFXW7E7M8T.jpg  AHOJOLKA6UA6.jpg  K755DD4LKY1L.jpg  SX9G372G1TEM.jpg\n",
            "1NNGTTSS78RY.jpg  AHRM6UPOA4HO.jpg  K7GTS7AKB1EZ.jpg  SYD58ONFTVFG.jpg\n",
            "1NZWDBWMJMBE.jpg  AIDLAYVI7HDW.jpg  K88E30SN44YB.jpg  SYVKBJTLJJ3R.jpg\n",
            "1O6HH4F3T5KU.jpg  AIQMEQYE175X.jpg  K9H1D7JLNE4H.jpg  T32NBXUTLKSS.jpg\n",
            "1OAT2ENWJ43W.jpg  AIWF5BXAZF5S.jpg  K9OD9C4VWM3I.jpg  T3BQAJ3897NB.jpg\n",
            "1OGQ1L195FTM.jpg  AJQ66FSONLTT.jpg  KA7FX0JVZD1F.jpg  T3G89X65G020.jpg\n",
            "1ONL5HHAD36Z.jpg  AOFKPFAMSISS.jpg  KA9C8F6WH0RV.jpg  T4B71KE5UXMO.jpg\n",
            "1OO419G00TN4.jpg  AUZWKKHITCRZ.jpg  KAN4CJNG3MP1.jpg  T4F29EF71XJ2.jpg\n",
            "1OW69Y40EBDI.jpg  AW5ZK12Z329V.jpg  KC81YGWTDI2U.jpg  T54B3LVKPM6U.jpg\n",
            "1PVD9AN9W6MR.jpg  AY89ES8RZOUQ.jpg  KCGCIITI206O.jpg  T57WV7HZF9H4.jpg\n",
            "1Q7D2P6KFV9I.jpg  AY93OCR05E88.jpg  KCOO572G9JZH.jpg  T5I9C3NE31WY.jpg\n",
            "1SYPY3AIWR7A.jpg  AYG5ODMKS8GQ.jpg  KEKCSENVC0TZ.jpg  T893SYZDF0NR.jpg\n",
            "1TSKKJTYJ9ZH.jpg  AYL2GMQMAF17.jpg  KEXB20SZEL7N.jpg  T8SX45DQ9PBY.jpg\n",
            "1W12MGLO3DU7.jpg  AZEQY8GB7W41.jpg  KF5USYHECY4N.jpg  T8UCHCTWNE37.jpg\n",
            "1Y0ADLEAOVPC.jpg  AZM81MWDX5ZL.jpg  KF8565XPRN4C.jpg  TAVGL6PCB9Q0.jpg\n",
            "1Y0G5F5LGK56.jpg  B18TFK1A04CO.jpg  KGIUSEIN7RQF.jpg  TBTDXK6G1XQO.jpg\n",
            "1ZH7QPR62CWI.jpg  B2E6OF9SUS61.jpg  KKCSGJZGZ7X0.jpg  TD0QRW5MAIIL.jpg\n",
            "20S9DBXLQ42B.jpg  B2RGBZ2MSK4L.jpg  KLGDKTN7TPYF.jpg  TDOXLE06TEEW.jpg\n",
            "24Q7M4ORNR4X.jpg  B2WI2JY9M06J.jpg  KOA9DZ9G562B.jpg  TDTK0QAXKLUY.jpg\n",
            "24YGN9BSKYBR.jpg  B3W8XB51QAX0.jpg  KOLT5Z2VMOTX.jpg  TE013W5UQCM6.jpg\n",
            "25FGSP7T29W2.jpg  B5BIMMVKTOM3.jpg  KQJ6P4CCT8Q5.jpg  THEWRZ54LPSD.jpg\n",
            "264OVSTUYET0.jpg  B5SY7E6Q3ZVJ.jpg  KQOK0XHCGZHA.jpg  TJXTVK3JM3VX.jpg\n",
            "26E777V3SJ4L.jpg  B6394TWQRHYQ.jpg  KSGSGNKE92BZ.jpg  TL1OJ4ZOT983.jpg\n",
            "2793PJ4K2QSR.jpg  B6AK64I0YAVG.jpg  KSYCP1U7FHOA.jpg  TLDLTRHLTGAT.jpg\n",
            "27QLAD1HRXOO.jpg  B6JS0RKU4YWW.jpg  KT9LFRIBTW7N.jpg  TLMODRLKDSHP.jpg\n",
            "28DX4B91W39X.jpg  B85N30KS70O0.jpg  KTQ50E9Y4CTR.jpg  TM4U31754ZQJ.jpg\n",
            "28UJ58C38BI9.jpg  B8BHZBW1LLDE.jpg  KTYBXN6RNEN5.jpg  TOIZPBY1AH3F.jpg\n",
            "28UTLKJFAX2P.jpg  B8MG6VJVYXBB.jpg  KUNA3T4O2JC0.jpg  TOJ2483W0EFT.jpg\n",
            "293V1UK8FSTG.jpg  BBJVFZ85VHWI.jpg  KW6QIDPJRH7W.jpg  TP0XSBWFFF17.jpg\n",
            "29YLUDSIEQSU.jpg  BBRH6HT4PGYR.jpg  KWC3O3SPTIF1.jpg  TPBUG05OVCCY.jpg\n",
            "2DU8D6XXJ3XM.jpg  BC2LXYUFK92H.jpg  KWSOBFT2UYWT.jpg  TRP8T2R8PGL8.jpg\n",
            "2DUF3GY30FRF.jpg  BD7LV68UGQYJ.jpg  KY193I3NNNGC.jpg  TRU49D7DODPU.jpg\n",
            "2EP6QFFGW3EW.jpg  BDKSSOPHW7FT.jpg  KY4SJMYA75D5.jpg  TT8O4B1QOBDC.jpg\n",
            "2FYATH6V4CAD.jpg  BDW5UB3420SF.jpg  KY72TFMLF2V8.jpg  TTECWFSQ9VZF.jpg\n",
            "2G0PM7HE3IBB.jpg  BEKTDV7AF36M.jpg  KYP634S2BXSO.jpg  TU55NSA0FA7X.jpg\n",
            "2GHMG4PVY37O.jpg  BFAMMSLWVHMB.jpg  KYQMRA9SFX60.jpg  TUSGJKVIVSMG.jpg\n",
            "2HCAM8ZFC924.jpg  BFI75D9IW8XT.jpg  KZ7BJMMHBMBZ.jpg  TXGL2RR2WIQ2.jpg\n",
            "2IANP0WLOTJ8.jpg  BGT1DZ9CVA4V.jpg  KZP7RJTNF6LR.jpg  TXLXVQ0VU526.jpg\n",
            "2JPDE4PVJ016.jpg  BGXZWX62W01Z.jpg  L0NHQUPJVCX8.jpg  TZWAG4W8AC2J.jpg\n",
            "2K7ZA322UZEO.jpg  BHR444925INO.jpg  L211OM7532CV.jpg  U4SXHDXA3JM3.jpg\n",
            "2KN4M917YLBF.jpg  BHZ0UAAL5PP0.jpg  L2C1RZNAYUNY.jpg  U5WEV8TO4B0O.jpg\n",
            "2LBFZPYEF16H.jpg  BJD0YJL31LSL.jpg  L2FBCKEGHRZX.jpg  U6C6WB0497F7.jpg\n",
            "2M077NZJCLOH.jpg  BK7GZ0O4Y6TB.jpg  L2J3W4HT6TQ2.jpg  U6TA2W4A8317.jpg\n",
            "2M82NBAAL7J4.jpg  BK9AY5KYNTFB.jpg  L2RENHHFGHYE.jpg  U7876DDIO97B.jpg\n",
            "2M9EMU0PBNHV.jpg  BKFWBZNUWFOD.jpg  L3763LRFUV0B.jpg  U7GTRZ0UVR4O.jpg\n",
            "2MLT1228NE3F.jpg  BKGL3F2HHADT.jpg  L3QBWWUEKSM1.jpg  U8PUXKHTXOB6.jpg\n",
            "2N95LW4T49WM.jpg  BKPGUW1JV9B4.jpg  L4OCHNY0ZORY.jpg  U9KX7S6JLPD3.jpg\n",
            "2N9YJIIZ7U10.jpg  BLLPW25XF6TX.jpg  L65LQNHUY8VO.jpg  UBMFQ4C9THEN.jpg\n",
            "2PI575Y6VUD9.jpg  BM2213RO1BB4.jpg  L6H9JE3HXWBL.jpg  UBP7JI0FI6M0.jpg\n",
            "2Q0T0WG89RU8.jpg  BMP75LGPL8MB.jpg  L6LHC7JF52JN.jpg  UDX6SJ2ZH5QE.jpg\n",
            "2Q38QCWYV186.jpg  BN7C3AWZPV7F.jpg  L6UMJKEI6K5R.jpg  UE0WR8ITPU0Y.jpg\n",
            "2QD3VJNQWAWE.jpg  BN9MHCWBMQAE.jpg  L70EE4WA14IX.jpg  UE310OZ7KUPI.jpg\n",
            "2QLTVT9C96EV.jpg  BPWRLC2UAORA.jpg  L97BVWDC5CU5.jpg  UGP7L2ISQKQ3.jpg\n",
            "2R6R0T0NYZVD.jpg  BQFT0SA12W17.jpg  LB87FMOUL24G.jpg  UHAQSEHEELO7.jpg\n",
            "2SC12KPYC8LD.jpg  BQGG0DV2OLYH.jpg  LD4P4UPQDTOV.jpg  UHW12LJAR0J0.jpg\n",
            "2TMBIO160YCA.jpg  BRMNQSKBSMCG.jpg  LD7RAQ9CLBAB.jpg  UKE19NUOF92D.jpg\n",
            "2XINZT5OB66A.jpg  BSZN01UJ1P6O.jpg  LDEAMRMPRHPP.jpg  UKI2IX8I9RH9.jpg\n",
            "2XTHRJGSYRYA.jpg  BT9349S7B4KD.jpg  LDEQN7E98G28.jpg  UKOY68IO0VAO.jpg\n",
            "2ZKW55F188EA.jpg  BTSI7YTQMYGY.jpg  LDRRBO99D3AI.jpg  UM66TM6A4CRU.jpg\n",
            "2ZQ3ZUYVRN14.jpg  BUWVIRX402TY.jpg  LDZMOZ5H8FUX.jpg  UN21310FWWZ3.jpg\n",
            "315S1OI7NX9F.jpg  BWQG2M72BPSI.jpg  LEHQHZFAUGZS.jpg  UNDN4FMLMNUF.jpg\n",
            "31B93J2SWEDT.jpg  BWYS6B2SXHYQ.jpg  LGJMOAU2NLHT.jpg  UOYQOBQH02DA.jpg\n",
            "31OA5UZPAJH2.jpg  BY4B7GGANUA4.jpg  LGUO8CM7FOM0.jpg  UP0KHFPAUZRQ.jpg\n",
            "324G0FJQQF6A.jpg  C0UTAKP1AJB0.jpg  LH8YHVW1E01J.jpg  UQEAAMVCQBN8.jpg\n",
            "32DW2A82ULHD.jpg  C1CZUJYO5U3V.jpg  LIJJ1MGO81RW.jpg  UQU8KUIXJRC6.jpg\n",
            "33632NMP8HOH.jpg  C26S283KWCZ8.jpg  LIP0XOKMW5IF.jpg  UQZ3TFG73N29.jpg\n",
            "3412FBORF7XN.jpg  C4NC80PX9PMY.jpg  LIXEZNOBAVE1.jpg  US4JIEEGSCYL.jpg\n",
            "34C6JEX97TSS.jpg  C6FJSPJ6TQWC.jpg  LJ7CG9151Y1D.jpg  USGZ8VW2QLNH.jpg\n",
            "35PW7A7Q23VI.jpg  C6TAGNJ3TYTP.jpg  LJOZRBPRJS0Z.jpg  UV24IS6KMBRC.jpg\n",
            "36ET5XD6TCHP.jpg  C7V1WSXM731D.jpg  LKTBLSDP3DYI.jpg  UVRODYARU7IQ.jpg\n",
            "36JGXW34BLIS.jpg  C9AG0WIRUDBS.jpg  LL48NF1F57SH.jpg  UWB4CMOC2SBZ.jpg\n",
            "38HXGX1LVWL6.jpg  C9T4SMJU4JNF.jpg  LLIURGK5BXN2.jpg  UWVWA2BJQDIY.jpg\n",
            "39TYMD70YGWO.jpg  CAU66PCB9D8Q.jpg  LO7X7SI9H8KY.jpg  UXGGVI558EUH.jpg\n",
            "3AQFREB3PHWU.jpg  CBO42MCFGXHW.jpg  LONLCSUXMU9H.jpg  UZVSTKDGA4AO.jpg\n",
            "3AZNS3PG1C02.jpg  CBOXYFTMR3V1.jpg  LOWN01W6RSZB.jpg  V0UJ1VU864GC.jpg\n",
            "3BGN8SFQL6R5.jpg  CCIV5QZ1W28G.jpg  LP5ZNYEIFCP9.jpg  V274OV61QNVJ.jpg\n",
            "3BKSTHFQXABD.jpg  CCUXTS4A6QAA.jpg  LP9L1SCZMPE5.jpg  V2RQYHOXHHTA.jpg\n",
            "3BXLCFUR295K.jpg  CD2HTW0KJOG0.jpg  LR61RFGBPN8U.jpg  V54KE603L9MW.jpg\n",
            "3BYLDLDESSC9.jpg  CD8I17P7GADM.jpg  LS9F0AZC9K06.jpg  V668LBPHIEPK.jpg\n",
            "3CUZ1A3HPRWQ.jpg  CEWN96QIRMFY.jpg  LT1PSXXGNO5T.jpg  V7ABIX8ITT7G.jpg\n",
            "3DI32J9XUO19.jpg  CFCRKHBIH3XX.jpg  LT45T282Q1YO.jpg  V9OFCORNTOC1.jpg\n",
            "3G1WKFH6SJ4M.jpg  CI4861VJZSBJ.jpg  LT62QYIS5LT5.jpg  V9QOG8IDSRT5.jpg\n",
            "3HN14OQL5Q0O.jpg  CKRW7NI4Z4D8.jpg  LTN09BV10AOA.jpg  VACIF5KX4ZB4.jpg\n",
            "3I0S1R9LKHX0.jpg  CLFTELRNXAYY.jpg  LU0TWWEQQFHH.jpg  VAKNN26XEGHN.jpg\n",
            "3I26DR1NL7BG.jpg  CLG92UZMPNKR.jpg  LUKTASYPIHTW.jpg  VB7FE7EPMPHU.jpg\n",
            "3IP3KGBDH4DP.jpg  CLZZWKDJ60TH.jpg  LV857J0WP8G5.jpg  VBP6OGCSTOF5.jpg\n",
            "3J1XQWICRLXB.jpg  CMD6ZJLBQE0Z.jpg  LXLQ3Z49PHYR.jpg  VBYJRAU1MG3Q.jpg\n",
            "3JD9IIEYK040.jpg  CMMJNH4MHKW4.jpg  LZJP64Y272M2.jpg  VCJNG17X7U2E.jpg\n",
            "3JK41CJGHM6W.jpg  CNU6B9O7G44C.jpg  M2P9GR6RAAF4.jpg  VDHZM8SQT3I2.jpg\n",
            "3JOVSHDTYE2C.jpg  COLRN3BZWV7O.jpg  M3EP7H8O9BFU.jpg  VF8LSAGQ2KVP.jpg\n",
            "3JWNON0W0SHQ.jpg  CPCC5E7SFP4A.jpg  M3G6M5XP14QG.jpg  VFK3FJXUSNU6.jpg\n",
            "3JZO3YQE3F7L.jpg  CPF4ZGQIERM4.jpg  M4ZAJ1XXPZH1.jpg  VGQXCWF4N1XX.jpg\n",
            "3KP57L92O4XW.jpg  CPR9ZCPBZ8GC.jpg  M5V0VTNA1HW5.jpg  VHPHS3SJOWTL.jpg\n",
            "3LNNJE4HRPX6.jpg  CQPM0EFZ2EE0.jpg  M7L5MEZFSHKQ.jpg  VHTOBBVKKOT6.jpg\n",
            "3LRLD6HUWMZZ.jpg  CRGHTROAT265.jpg  M9587SIRTJN9.jpg  VIHJ4JRS0Z7X.jpg\n",
            "3MFY3ZZPKBXA.jpg  CSFJE0SVEHU4.jpg  M9EBDY8I2K84.jpg  VJNJA7AHCV9S.jpg\n",
            "3N5RZBMWHM6I.jpg  CSL1KDDL0ZF0.jpg  MB9WHYXPNIJF.jpg  VJP9V3B5RUT3.jpg\n",
            "3N8VBAPOY11K.jpg  CSZI2G9PYWI4.jpg  MBCNMEZ1P3GZ.jpg  VLAN4G4JTJ22.jpg\n",
            "3R3H3VZQB04U.jpg  CT0P0BIT8S91.jpg  MC4EHPBMA46R.jpg  VLP6GTLXVBBK.jpg\n",
            "3RH0FEOTHRYS.jpg  CT3T45VE2PWC.jpg  MDKVO495LDLL.jpg  VLT468M7IYI7.jpg\n",
            "3TQ47V4IXNI6.jpg  CTXC6AIX2OJM.jpg  MEHFB8CYZA7H.jpg  VML3NM08CTW4.jpg\n",
            "3TS2PJV2ZQAD.jpg  CV2EKTS6102D.jpg  MEOWJCA2WBQT.jpg  VMODB2C6QG6S.jpg\n",
            "3UDVVIMVXZAJ.jpg  CVTPGXB8FT6P.jpg  MFHOI78LDXDL.jpg  VNFMGSC88IS6.jpg\n",
            "3UDX6LF7GTT5.jpg  CW358KFLUCX4.jpg  MHJDP152PMF1.jpg  VNZKJWZY3ONY.jpg\n",
            "3V2BHQZRHFZ8.jpg  CWER6Z0VDFWE.jpg  MHZUGOL59CIN.jpg  VOOHB2X8FJIV.jpg\n",
            "3WMJIU6Y7UOW.jpg  CZFOMH7YF062.jpg  MJ79H931NT6L.jpg  VPVZBOGJCJPO.jpg\n",
            "3XH9DNYHIEN9.jpg  D02VRUTCPAGK.jpg  MKD0RRLWXQU2.jpg  VS2E7965GGI1.jpg\n",
            "3XQ8GQA2I9H1.jpg  D0NDRL9W9IDE.jpg  MLNMY20HDGC8.jpg  VS6UNQ5LB2SZ.jpg\n",
            "3XTJRK6MI1A7.jpg  D16OB00MYQL6.jpg  MMNRT9OANNBN.jpg  VSCOAKXEKE6Q.jpg\n",
            "3Y2SKPRT2L16.jpg  D3OU67KHLMT8.jpg  MQ6WG24V92JV.jpg  VUIEQUC9YA3G.jpg\n",
            "3YJE2RF5M4ZY.jpg  D4HIA2BAEECG.jpg  MQW2LUKXGK9A.jpg  VV4AF3P5A5QG.jpg\n",
            "3YKI90KYE7D6.jpg  D4VCC0QAP9BX.jpg  MRUOKMGICOLN.jpg  VVUYEMRAJKJU.jpg\n",
            "3ZE3Z9PKK85W.jpg  D76RW3JWQC9Z.jpg  MS14INWL4YFZ.jpg  VVXEY8VUELW3.jpg\n",
            "3ZPJ3Y8INJ56.jpg  D9L5GYJMSLRS.jpg  MSO6SY4O688H.jpg  VWZVOO2ZXKMA.jpg\n",
            "408EVNCKQYJE.jpg  DBYPBJLNDSXU.jpg  MUOEH4SW6MMF.jpg  VYFH8QCBDPWE.jpg\n",
            "424DSAY2R7C4.jpg  DCCVF2KKQAU2.jpg  MUWQ4I6HHO6M.jpg  W0WD3NFG6VQ8.jpg\n",
            "42ET2MHAT7XO.jpg  DCODH4WBJZ0Y.jpg  MVNKSWELBLPP.jpg  W1J3TY4ZI8L4.jpg\n",
            "43FG2DEWP15H.jpg  DE0SOX06P3RW.jpg  MWGP2KJJF5IY.jpg  W25THC7B7SZB.jpg\n",
            "43PI51GIAXT5.jpg  DE8FAZACNBGU.jpg  MWP81SR5VWK3.jpg  W2CN99YLJI04.jpg\n",
            "45YO0LAQSX9Y.jpg  DF0URBD39UBW.jpg  MWXBUKUAZMBD.jpg  W2CZ8EODS23U.jpg\n",
            "46BBXXDHS9GG.jpg  DF1M6LXB6X9S.jpg  MXC7DSR4Q36H.jpg  W2FE5MUUQA6I.jpg\n",
            "46OU6FG27OCX.jpg  DFHZ9D9TQQNB.jpg  MYEVEIKFHH4Y.jpg  W5IN6P4KDN1S.jpg\n",
            "47K82TIJGJUG.jpg  DG8YXC06IPRP.jpg  MZ7CGUOLA0DM.jpg  W5JIMCK22Z0X.jpg\n",
            "48PD53Q9WMRY.jpg  DGXT3M84JUET.jpg  MZUYUGEPJLI1.jpg  W645E17AWZ32.jpg\n",
            "4ARCGVNVCO1P.jpg  DHC42TMV9Z7E.jpg  MZVPKQD6O4IE.jpg  W6JB28AN3QDV.jpg\n",
            "4AU6Z4RS1TDF.jpg  DHSJ8FCJ1BT7.jpg  N01G19CYVYRE.jpg  W9DQGJ5Z37PM.jpg\n",
            "4BCMO8V97D0G.jpg  DHYTLGHKE3SN.jpg  N3KPLWBP8K25.jpg  WACMC02XVT4J.jpg\n",
            "4BY332HQ02F3.jpg  DK8J4K10DIFR.jpg  N3R1XY1PKWKT.jpg  WBICXAX43R73.jpg\n",
            "4C5GCCHPY4AT.jpg  DL7HSFGLG81M.jpg  N3XEAEFKMHEV.jpg  WC53L9N7BCNE.jpg\n",
            "4D8ZMLR0651M.jpg  DM2SFV06RI81.jpg  N56U1JAF0KHP.jpg  WDATCUCOK52D.jpg\n",
            "4E4VSFL138T4.jpg  DMXPQ3AC86Q3.jpg  N5XU0OLEMFMI.jpg  WDLDXGN6HH7L.jpg\n",
            "4EACT114LK93.jpg  DMYM4IGIXJ0O.jpg  N72V9WHRT0G1.jpg  WDLUUV51PB67.jpg\n",
            "4F2AF1159JVM.jpg  DNAK1XLPF4EI.jpg  N74KB2SYQKFI.jpg  WE07VE29J25O.jpg\n",
            "4FISYIF3MSHC.jpg  DR5FMNXDTH6P.jpg  N7YCHWKVF4UT.jpg  WE20U7DP7DH2.jpg\n",
            "4HHBMAVX798B.jpg  DRH5FQ8415V3.jpg  N89ES1B1C5Z7.jpg  WFPWGBCMOWU4.jpg\n",
            "4JBMT979QUE5.jpg  DRSSJW9V96F3.jpg  NAGB5EGF4GJN.jpg  WG29IF1GLR5M.jpg\n",
            "4KPD7J2NX2HE.jpg  DSK6YVEOEB6N.jpg  NCVUO8UOHNKT.jpg  WJLU8QLZP9N9.jpg\n",
            "4M9Q99JDKEBQ.jpg  DSM70LNDN04G.jpg  ND5CHTR17VPO.jpg  WK98PFDNORG2.jpg\n",
            "4MM02HDFXVJW.jpg  DUEJ1RWO6TIV.jpg  NDWZ5PUJ5USW.jpg  WMX7PZ9YLQF1.jpg\n",
            "4MNK1ZYWAUA8.jpg  DVSEU3OZ0I7L.jpg  NEY2ASLPWNPS.jpg  WO7K9HLHALJJ.jpg\n",
            "4MY4SVUCYCV4.jpg  DVZU4DZSR034.jpg  NG4LWOG2CDEC.jpg  WP3JVHZCGCZJ.jpg\n",
            "4O6WI469NMN9.jpg  DW9OK9WXELES.jpg  NKGON0YY53V0.jpg  WPCNAQMR8KCD.jpg\n",
            "4Q0J03UAZULE.jpg  DWSACESF880A.jpg  NN0OYXDAVPO2.jpg  WPE88WYLOPN7.jpg\n",
            "4QAM84GKJR87.jpg  DYFI9KELPTZR.jpg  NNBNG92NT7R1.jpg  WPKZ1I6ZJQQG.jpg\n",
            "4QRCWKPT3CCX.jpg  DYMPV6G51LX0.jpg  NO2K4A32EBYC.jpg  WQOXPY46K4ZW.jpg\n",
            "4QU8WP672T53.jpg  DYSK0HVCGSCZ.jpg  NO3RLZ0HNAV5.jpg  WR9BRVIVPBS2.jpg\n",
            "4QY00EKJPMHE.jpg  DZDDO5DGEMBL.jpg  NOG8HKGAB56I.jpg  WRJGPDIB1K0Z.jpg\n",
            "4RFCP6E9EIZH.jpg  E2QGL5LQD5XD.jpg  NQ4G5D1HX0B0.jpg  WTRV50JH4D7D.jpg\n",
            "4RVT2ZTF2FB1.jpg  E33LQUUOYH38.jpg  NQMB2KSEDVJK.jpg  WUALOZDEF8E7.jpg\n",
            "4S7ZX1EKTQ50.jpg  E380GBCXBDT7.jpg  NT47NKZU224A.jpg  WVZ07R2W2AGR.jpg\n",
            "4SANMFC2OPZ9.jpg  E68GWSG9O31C.jpg  NU5ZDQY5ZHT6.jpg  WW5UJS4CMPF8.jpg\n",
            "4TCEQYLVHM6J.jpg  E6AK0PDVB0BT.jpg  NUCU4MS5TNWL.jpg  WWBTJSPQSZA3.jpg\n",
            "4UU3C3J88N3A.jpg  E6EVKCQ2JBSN.jpg  NUUD3CJK2RHB.jpg  WWPD0OG77XE0.jpg\n",
            "4VASMKTXW3C5.jpg  E6QOIWN9XUPA.jpg  NUVXIOIKXQF2.jpg  WYBWU6ZL5CVZ.jpg\n",
            "4VDJ7TIMIWC5.jpg  E7A9A01BVTMT.jpg  NVB6AASYCUT6.jpg  X06XIL74RQOQ.jpg\n",
            "4WPUIL9G2QYY.jpg  E8S6SZG2QIKN.jpg  NVEFBWP67HWV.jpg  X1KX34GZ271K.jpg\n",
            "4X0LPH5DU42O.jpg  EB5GAAJMB7JZ.jpg  NX2DQXV016BC.jpg  X1L95ZPH4NID.jpg\n",
            "4Y4FM59ZJOTM.jpg  EB7QEXW1NLS1.jpg  NY1V5TTKJPWN.jpg  X1ZFLAN0QE23.jpg\n",
            "4ZJ5N9L32BUO.jpg  EBJPB8LXHK82.jpg  NYTBUNGO82I4.jpg  X2B597B4WNF9.jpg\n",
            "4ZN6R5VFCSPH.jpg  EBM2HGUOSHE8.jpg  O0I5VWUO0JF3.jpg  X37TP8QDVHU9.jpg\n",
            "4ZT4E9SPOW1W.jpg  EDA61UESFRE0.jpg  O0LNGLR79Z2M.jpg  X3EWLSI2FDBM.jpg\n",
            "50J85QOVSTPF.jpg  EF625LPFM5UB.jpg  O0P8AL68I9HJ.jpg  X3FBORDS652S.jpg\n",
            "51AJ4J33A7VM.jpg  EG9K73EFVPBB.jpg  O28EIBJR066Y.jpg  X4KD05BSZKBZ.jpg\n",
            "51DZE3B57XW0.jpg  EI4ICSXOF6VD.jpg  O2RY16N4ZSSL.jpg  X6SLAEZ3LK4H.jpg\n",
            "51SU6IIZS7K5.jpg  EKTTOZ3JGPJ0.jpg  O388797314B5.jpg  X7LUOHV4MCOZ.jpg\n",
            "52J9BY1AJ3U0.jpg  EN38P7O47EXV.jpg  O3KTT0OE2EA1.jpg  X8J7D9CADVOD.jpg\n",
            "54PEZVPWHID0.jpg  ENN40N0MJCPM.jpg  O4GAH8W9H3GE.jpg  X8Z1B09FXM1N.jpg\n",
            "56OLEO07D7T9.jpg  EPWK5GQ6MOZ2.jpg  O6G4MFMT2327.jpg  X97NOVQECJ00.jpg\n",
            "56ZY9DL9TVBU.jpg  ESF1PS4EPCXX.jpg  O818GAFJCBQG.jpg  XB6S9IEZENYY.jpg\n",
            "5B0DM5RJ0GMV.jpg  ESGD39J1DK2Q.jpg  O87YYUGDB73E.jpg  XBMY48AYLTLZ.jpg\n",
            "5C25FIQCGJR4.jpg  ETOHMM90GKJT.jpg  O9SKB0I73GUL.jpg  XCWQQODSK31Z.jpg\n",
            "5CWPKNRG5062.jpg  EUMEM6YE0T4Q.jpg  OAVESW8D5UL4.jpg  XD21UJR9MNU6.jpg\n",
            "5D2GX1V2N1OO.jpg  EVB0G7MAA20Z.jpg  OBUUWEHLCWZE.jpg  XDFK3UW7RB1R.jpg\n",
            "5EAW33RWLCH9.jpg  EW7LV6FNADZV.jpg  OCG2K8MWE72Y.jpg  XDWKY1VN81HP.jpg\n",
            "5EE1EH5J6JJU.jpg  EY05J1BW6YP1.jpg  OCSM4BGHOO9G.jpg  XFEX9JKGGA3F.jpg\n",
            "5FHK023710DG.jpg  EYB2HU0XC8NZ.jpg  OCYRVJNW0L1O.jpg  XFSYQSC80X59.jpg\n",
            "5FRHQZ0UBIKY.jpg  EZU0L10DCM4O.jpg  OFZLKCPR3L3V.jpg  XFZBTDYLGACR.jpg\n",
            "5H6KG8JO4A97.jpg  F013IX17IN7I.jpg  OGVWI1H2QXQ4.jpg  XHFJ8Z95ER81.jpg\n",
            "5JF6S6EL3LXL.jpg  F23ZJFNENR24.jpg  OH5QS9GN3EOF.jpg  XIAWP8CHO45D.jpg\n",
            "5LV1NTE08UUG.jpg  F3FBD9N70V90.jpg  OIX9B5P6C862.jpg  XJAFUASP4FC5.jpg\n",
            "5MT64RWSO08N.jpg  F3MF7W41253R.jpg  OJG7JI1A8E17.jpg  XJXZKC5KGM0Z.jpg\n",
            "5MYUAE2OMWMQ.jpg  F3Y5KG0IIYIQ.jpg  OJVZNV9ZG9P7.jpg  XK1CYP0WI8LM.jpg\n",
            "5NPFEQUKOYHL.jpg  F431N6AKPWA2.jpg  OJZOOIX6CIN1.jpg  XMB5OS82UDJL.jpg\n",
            "5O5COK6LXTZ7.jpg  F455JTT2PF2D.jpg  OLHNYPX8OCQL.jpg  XMR7JIVFTJ4O.jpg\n",
            "5OPF1D9IJ508.jpg  F48M84SH5NME.jpg  OMQYITXIK6DC.jpg  XNWAGLNV74KB.jpg\n",
            "5PEJ8Y7380WB.jpg  F86XYORAY8XD.jpg  OO5YQT2JJ2T9.jpg  XORBZ4N663ED.jpg\n",
            "5PJE3EHTR4UI.jpg  F930YO3PQGP9.jpg  OR7CHJOK92EE.jpg  XPU1AWQWL6FO.jpg\n",
            "5PV73LQY36L5.jpg  F9UVSLI0NLTD.jpg  OSNF2ZMQ4CG1.jpg  XQ15925JXMI0.jpg\n",
            "5QS730DW5BW7.jpg  FA3OIVKRF6WU.jpg  OSWIY1ZFNMJ4.jpg  XSAFM66FQ4LY.jpg\n",
            "5QSDFRVWW2XL.jpg  FA9UYYK79CTA.jpg  OTAWDUGQ22BX.jpg  XSFKCDM00KG2.jpg\n",
            "5RGK5HXBDNST.jpg  FBF3S8A7X860.jpg  OU4EML4JSQJS.jpg  XVE36WXX3XAR.jpg\n",
            "5S51KBT07HW5.jpg  FC5F8J28KOKS.jpg  OVYY2A8J9XVI.jpg  XXGV85XH3Z7H.jpg\n",
            "5S5KH0BQ51NJ.jpg  FCE1PSBEO0U1.jpg  OWLFZEBWKKB7.jpg  XYQMY526OAX4.jpg\n",
            "5UZBS5RZZL3K.jpg  FD3CCKHUQV3T.jpg  OWU7N999W4CG.jpg  Y0HEBZPL00E0.jpg\n",
            "5WDBTNCTIZNF.jpg  FDEOK0QLFM5Z.jpg  OX02ZAMEPXRE.jpg  Y0NHXTCYSAZ1.jpg\n",
            "5X07QZHKAGBX.jpg  FDLL4BKZRFKY.jpg  OXIC8ST3K656.jpg  Y1ACDQZKGTTT.jpg\n",
            "5Z73BS52I8C4.jpg  FET51RDJOEI5.jpg  OYLL8O7E1DGZ.jpg  Y1HIHMEIKOEU.jpg\n",
            "606O8MLX8ERR.jpg  FF0PGSR2DCPI.jpg  OYUMBLTP71GK.jpg  Y1PUASFNLLBS.jpg\n",
            "60J046TFQBHL.jpg  FFPI1YFYDT6R.jpg  OZ9XXMUAWR3M.jpg  Y2FJMMI9G6GP.jpg\n",
            "60T58AK2WSY3.jpg  FG1OHPKNYJUG.jpg  OZICC2U1TGTF.jpg  Y2STI6D3TIYZ.jpg\n",
            "611F2A5AWR8K.jpg  FGPQW1RI0ZKG.jpg  OZNHAWNINUCE.jpg  Y3234NXRP46L.jpg\n",
            "6199E6KU6N0F.jpg  FHWHRCETKDQA.jpg  P0CILCVLHDYK.jpg  Y3KSG4FKYB98.jpg\n",
            "62Q3O7ZQEOXM.jpg  FKB6GJ3053H2.jpg  P0FBMP661MM8.jpg  Y3YO3GR7Q11F.jpg\n",
            "63C3BQFB3VF4.jpg  FMEGO7UN10F8.jpg  P0OBFFKQFPLB.jpg  Y4J99FK6BW7F.jpg\n",
            "63K70ECB7YD3.jpg  FMR385EP9NOL.jpg  P0R1MYHFYXRF.jpg  Y550IUF9OVTW.jpg\n",
            "65JP2HLK2O58.jpg  FNVLOG3EOL5J.jpg  P28WSB6LRXUV.jpg  Y5IJHQHDDYGG.jpg\n",
            "68KSVX2OKOXG.jpg  FOGMQQNIRL05.jpg  P2DCA3ZY6XL3.jpg  Y5JDATJQ7YXZ.jpg\n",
            "69J0KTGCCVE5.jpg  FOIJEPKI1CPT.jpg  P2RG4MERJO58.jpg  Y5ORLI4RL7WF.jpg\n",
            "6A52KJP0N2KX.jpg  FOVYID8J0XQL.jpg  P2VC0ANRJSTH.jpg  Y5OUYZAPY975.jpg\n",
            "6AH8HP9SVHD0.jpg  FOWX3ZUIGFMG.jpg  P2Z9WYYKP7JW.jpg  Y6PSWU9T1NNO.jpg\n",
            "6C9347NTB3XX.jpg  FP8EV4COOL2M.jpg  P3USYS1B1E2Z.jpg  Y8ZEV5HETYTI.jpg\n",
            "6COM49SAFHO5.jpg  FPJAM04IRXPB.jpg  P4U8524GMKVF.jpg  Y8ZFAMZJ1UW5.jpg\n",
            "6CXH4ZX1RR46.jpg  FQ3HTKC1DPWA.jpg  P50ZF86CR65U.jpg  Y9MPR4GZEA3W.jpg\n",
            "6DUJ02MDC8NS.jpg  FQD6VDXFKYA1.jpg  P6TJXLPXCQ8N.jpg  YA32H7YDA07Y.jpg\n",
            "6DZD2MPN6OHK.jpg  FTGKL3OWWXJW.jpg  P8BRXHKJ37CT.jpg  YAG5GUMB5ODV.jpg\n",
            "6E571IFMND59.jpg  FWJGZ24COD1R.jpg  P8NX9C9KFEGY.jpg  YC74JG4EENKP.jpg\n",
            "6FWKKZ26Y61C.jpg  FWJNGP1DUZM5.jpg  P8TTMBWNU0XJ.jpg  YDRA3WVT7HFY.jpg\n",
            "6H1KCNLC4BPM.jpg  FXE1VTV0M15W.jpg  PA3JM3GL1TXX.jpg  YFBUGPOTDC0M.jpg\n",
            "6IX4VUBA3W8M.jpg  FXVFS7R8RUN7.jpg  PAFQVUR60HNI.jpg  YFZQ203SYRWZ.jpg\n",
            "6KYWNR8GSV4Z.jpg  FYTPBF4LY19R.jpg  PALWE8DF37UR.jpg  YGZVV93KJM68.jpg\n",
            "6L0ZON64O8VI.jpg  FZBSY4JKIGVV.jpg  PBW0LNN7XUF5.jpg  YH3MRKUIJWTS.jpg\n",
            "6LAL7DWZRIVT.jpg  G1U5BXV71HZH.jpg  PBX63FSITEFA.jpg  YHDWOQQGI221.jpg\n",
            "6LY1N1BVR4VS.jpg  G2GWLBMGNOBC.jpg  PC33G7WZKSOK.jpg  YHFMAUPZNDUM.jpg\n",
            "6M512SXX7YCT.jpg  G2L2ATI5SYID.jpg  PCHC3E5FJC7Y.jpg  YIS849S2CF52.jpg\n",
            "6MZUJ4NJNKUW.jpg  G2PM24A98XQG.jpg  PCMUFXKZFU2G.jpg  YIY7W0CCDIQO.jpg\n",
            "6O8XMMS0JX4F.jpg  G2XZOPZIBAP0.jpg  PDP34PQERO9Y.jpg  YJBDAV85VSS9.jpg\n",
            "6QXKU3JV8IDO.jpg  G3ACE5CIGXRJ.jpg  PELK39XAJBBM.jpg  YK74X14PC6V3.jpg\n",
            "6S1CXO7IJGU6.jpg  G3ZVWU7CW4EK.jpg  PFOMAHDXUX8X.jpg  YKF56S5O0AS5.jpg\n",
            "6S2RV70Z2ZRZ.jpg  G4ZY19E2C3S8.jpg  PG563OHR6KBW.jpg  YM26MIS0R1E4.jpg\n",
            "6SRJYFRNP77Y.jpg  G5L6FV6HNTIU.jpg  PGBAL4KJPZYD.jpg  YM9C21DUX5RB.jpg\n",
            "6TCC2HOF7IIR.jpg  G7HNAM8GWFUW.jpg  PGPPQ6ZIIPLX.jpg  YN3RI0RJGICY.jpg\n",
            "6UOBO90E6CKW.jpg  G928NHN4GD6X.jpg  PHU8REP5R1YK.jpg  YO1XFOW0CAX7.jpg\n",
            "6UXPUKL0KRFH.jpg  GAHFZM6KH7GC.jpg  PI01PVIC08CL.jpg  YOYP7CCYV68O.jpg\n",
            "6VS9A62AUUG4.jpg  GDJ5HWHC3VOZ.jpg  PI10N13OIGH8.jpg  YQ8LS27YFI14.jpg\n",
            "6X74MRHLXFNE.jpg  GF3OXJRQONFI.jpg  PIGC0GFKNKJ3.jpg  YQH8W4E9W8O3.jpg\n",
            "70USB05A9I4E.jpg  GF5GOWOUC522.jpg  PJ3I37VKLEDZ.jpg  YQNOGAO8M40G.jpg\n",
            "713B1GMP04AC.jpg  GFO20PFF5GA9.jpg  PJ57VXB1KPZE.jpg  YQQZQYAOIOX1.jpg\n",
            "716WON9JF0KV.jpg  GI2CM4DZ8SRT.jpg  PJ8YEHEV2X2I.jpg  YRDKSWYTMSUU.jpg\n",
            "739PIMR5PRQX.jpg  GID74SWBXXSX.jpg  PJBDKOJ30WNB.jpg  YTR8B8CYZ4DA.jpg\n",
            "73N6L4HIXES2.jpg  GIYE4GZ61ZB0.jpg  PJRZXFGLXWMG.jpg  YVO6SJSWJV7G.jpg\n",
            "7476MUFKL66K.jpg  GLE3H9GYOV8J.jpg  PJWCVUIHP0BK.jpg  YY618B43KS4F.jpg\n",
            "75Y2E553Z430.jpg  GMCSEQAICTTN.jpg  PKH080VRTU2M.jpg  Z0BCVD1O5OMS.jpg\n",
            "77FW68ISVYCX.jpg  GNA48PQAAYQ0.jpg  PL47Q8RPP1OS.jpg  Z0EN088M5I30.jpg\n",
            "77GSRE5SPRFP.jpg  GO87WPWPEL7M.jpg  PLM3PG44ACA4.jpg  Z14AS3GG31QH.jpg\n",
            "783ZAP2CFE16.jpg  GP84744MCZZX.jpg  PMU6NVMA8T67.jpg  Z2UEPH5J2RVJ.jpg\n",
            "7878F46ZTNE9.jpg  GPAEZBP4Q94J.jpg  PN89C6SWC8XV.jpg  Z52B6Q1NP6VC.jpg\n",
            "7946ZA09FREI.jpg  GPS07K118GPJ.jpg  PQR65SGWUD86.jpg  Z5UBYB2YAOIA.jpg\n",
            "7A192S2AOX46.jpg  GPZBTENSFDP9.jpg  PQW71JI7A1GW.jpg  Z65QXU8XRR33.jpg\n",
            "7C5WE67YH9U9.jpg  GQWMRSYRLW5C.jpg  PRKD8ZBMUB9C.jpg  Z6XAMPUJ34WS.jpg\n",
            "7CJBWCVFHGWS.jpg  GQY0I2O2E1C1.jpg  PRL6VKTEJ75I.jpg  Z89TRZHAQ4UL.jpg\n",
            "7CK6PTTO8LA7.jpg  GRNMAC3GTXW9.jpg  PRMFF05HYKXA.jpg  Z8LG7A9V872J.jpg\n",
            "7E1AHSV4YBR2.jpg  GTAHMD2UEEDD.jpg  PROMGZ4GY3U5.jpg  Z9IDP7MI7NXV.jpg\n",
            "7EFER4HIMFCV.jpg  GU4HGDXNUHAZ.jpg  PSNTRGW9J7JH.jpg  ZAN6Q7ZZZEPK.jpg\n",
            "7FFG6V9WY51I.jpg  GWU7570BBJRA.jpg  PTLQYTYB9N67.jpg  ZAW9NFB9YYCT.jpg\n",
            "7G09NSEWULFT.jpg  GXATC154TG34.jpg  PTZ19KV9C3TW.jpg  ZAX9U2IVP7XT.jpg\n",
            "7GDY7EA81BZ7.jpg  GXZ0UZ573WOE.jpg  PUYPBJR3C8XN.jpg  ZAZ446IJ35S7.jpg\n",
            "7GE376820SW2.jpg  GYL2JIYTCHCJ.jpg  PXRWL4WHFGE6.jpg  ZB3XK7CXOLQO.jpg\n",
            "7GNQYBT5MHFW.jpg  H00WKGOWG0XH.jpg  PZSKJFHJ6209.jpg  ZBLW3ALRG5QM.jpg\n",
            "7HSJ2199J4T9.jpg  H01SDA0M6O0Z.jpg  Q05OI4W7Y9QJ.jpg  ZBOMDUQ6F1Z8.jpg\n",
            "7IOVCJMEAS0Z.jpg  H0GSPEC6UXW5.jpg  Q0NB2G5P1D9Z.jpg  ZCPVUCR45VAI.jpg\n",
            "7J2QLPXZDVVO.jpg  H0JM88VIT33I.jpg  Q2DG00VJ2DLO.jpg  ZE1X287YG3VU.jpg\n",
            "7LK05105FZBQ.jpg  H1UWF7SJN72H.jpg  Q3A70FANRR24.jpg  ZEJG2DKUJD8Z.jpg\n",
            "7MBR31FNYVDI.jpg  H2TBF4FP3ZPI.jpg  Q449SEFEZNDF.jpg  ZELHYOZKV7DM.jpg\n",
            "7N2FQMFLFGGD.jpg  H8TTP12VMCKB.jpg  Q4HIVPAEDFDP.jpg  ZF9ZDGFZQU1L.jpg\n",
            "7OC814AAHF5N.jpg  H901ZOMIARX1.jpg  Q57NG3LS764I.jpg  ZFUQGH3V402G.jpg\n",
            "7PKKLXN95SM2.jpg  H9VNEXI9JR78.jpg  Q5KED3B5X12A.jpg  ZGSE2JUB8GKH.jpg\n",
            "7PLWT6YVLEOD.jpg  HCLKO7IFGUBK.jpg  Q750FPH4LL2S.jpg  ZGSEO59VANKJ.jpg\n",
            "7QQGTU4XYG1D.jpg  HD483VNLU1JY.jpg  Q7DGZIMUXC87.jpg  ZHAIFNR1DTZ6.jpg\n",
            "7TB88ZHP8RG0.jpg  HDA457026G8I.jpg  Q7RXTIJICT0U.jpg  ZHZGLXDAI1Z9.jpg\n",
            "7VF5IU3L25GQ.jpg  HGBSE2JEG77W.jpg  Q7W04KI6SXTS.jpg  ZII4584ISGE3.jpg\n",
            "7VH7WZ58NXX4.jpg  HJ3Z8R56IPUW.jpg  QAGUHO18M3YG.jpg  ZIV0K6MEGS3O.jpg\n",
            "7VU6IDUNDT03.jpg  HJG0CE8K1F9E.jpg  QCRM2K51LQ29.jpg  ZJ2UVER53EGZ.jpg\n",
            "7W9S7FID0TR3.jpg  HK8F5R6W1A49.jpg  QD1PZJON7TL2.jpg  ZJ2Z4M4ZY5KI.jpg\n",
            "7Y7ZTJ4X5VE6.jpg  HLGF8ZLC7LMA.jpg  QE89RMH4N84W.jpg  ZJTYT3FSMFU7.jpg\n",
            "7ZDKAZ83QG28.jpg  HLK50LD7YK0P.jpg  QEDO1Q2DH1OM.jpg  ZK4YGJ4FKBPG.jpg\n",
            "81FL0H0VB7YQ.jpg  HM798NXSO95G.jpg  QFZV4E8UJVD1.jpg  ZKEHR78LPFUD.jpg\n",
            "81WO4SMIBUR4.jpg  HNBB5HEEN72T.jpg  QGR679DZDFCM.jpg  ZKF92HIF1EBN.jpg\n",
            "82UGRJMATHX3.jpg  HNWWZLF2ED12.jpg  QI5IDCTR6606.jpg  ZKR3WLQMIQF1.jpg\n",
            "82XPKYN648WV.jpg  HOKOSZ9B30A1.jpg  QJNK9RP373HF.jpg  ZKTEK5G75UY6.jpg\n",
            "83D8MEPKBWD8.jpg  HOKQMTDU32LX.jpg  QJZSU9BNJPXY.jpg  ZKVAC7SREIJW.jpg\n",
            "83MZ6QSJ0TB3.jpg  HOVFMV7TDIE8.jpg  QKJE70E4A5R3.jpg  ZL5EQQKM5HOB.jpg\n",
            "85P63K3Q02JR.jpg  HOYHQPINP0RM.jpg  QLFP83XFOT2Y.jpg  ZLIE0YUZ3TLY.jpg\n",
            "86ZGUAV11S33.jpg  HP0ZHMQDD5CH.jpg  QLIDJO7WYD23.jpg  ZNSMNR94W3AL.jpg\n",
            "88QF65BQPMD8.jpg  HPEMMVWI7YH7.jpg  QLMCMIKV68HF.jpg  ZNWH3I48HTIM.jpg\n",
            "89OP0REQFVCY.jpg  HPO55X44S9A1.jpg  QM6ZJ4DOJ5VY.jpg  ZO2WVBMYM8HX.jpg\n",
            "8A30G7GSCHHU.jpg  HQWSX75WQUHO.jpg  QMA2DBGX6ADU.jpg  ZPHNT1H9MP7G.jpg\n",
            "8AKP3WQI2DA0.jpg  HR9HKN29NED4.jpg  QMIGISSJGPCN.jpg  ZPV7POBR94XO.jpg\n",
            "8BCSPZ53N8PA.jpg  HS9O4ERJ979W.jpg  QN5A7RK7Z6N0.jpg  ZPX2UJHZX2M8.jpg\n",
            "8E7ZJRRM62VL.jpg  HSFRI5BPA1EE.jpg  QN8ZQ24IC0W5.jpg  ZQIWD4CQTMYY.jpg\n",
            "8H82NHS5PNYQ.jpg  HTG7WQ67W27T.jpg  QNCKYZNCGXTB.jpg  ZQURAMZMYC61.jpg\n",
            "8I6IFRA1B37E.jpg  HU5GG3X8HFDG.jpg  QOJTX6RRBGRU.jpg  ZRJCGXO9V9FC.jpg\n",
            "8JOI0DT0G4A2.jpg  HWUSISMEWNAF.jpg  QPY44ZSS3LRL.jpg  ZS4BAQD5591N.jpg\n",
            "8JUMSF20YB3R.jpg  HXBVRCIJ5H9I.jpg  QQDYG1A1NMX3.jpg  ZSA9NAML7TPJ.jpg\n",
            "8JWGSUZMLBZX.jpg  HXL45GMU3ZL2.jpg  QQXNEKFV515X.jpg  ZSBYG6DS23M2.jpg\n",
            "8JZX9RZXHDR0.jpg  HZ0E1KDOK0YP.jpg  QSQAKE7HA58M.jpg  ZTTVMXHUJNTW.jpg\n",
            "8KE2IU7C5MAN.jpg  I03N4BJ3A3UU.jpg  QV0FRFCRMCG8.jpg  ZUCX7ZHG87O2.jpg\n",
            "8N9WB3BSICVO.jpg  I1U8MMJTU7VO.jpg  QVQFXC9FL3LR.jpg  ZUDH6GFL8VYR.jpg\n",
            "8NF896RG5ISI.jpg  I284CK13342Y.jpg  QW1HXZKT02IU.jpg  ZV2Z4OFSG678.jpg\n",
            "8NOSAL29BWLY.jpg  I2YLPPXYX22A.jpg  QXDL8XO9W9QV.jpg  ZVDZ0EZJRGP2.jpg\n",
            "8OM7AX0W7JFU.jpg  I3QRF8W871VB.jpg  QXKG1K4RZ4AY.jpg  ZW1ZP03OZU0U.jpg\n",
            "8P5M6O75D6CG.jpg  I5BU8HT6ZSEQ.jpg  QZ1YZ7MG1Y1G.jpg  ZW9M04TMD3A5.jpg\n",
            "8P6SYN2TIYFE.jpg  I5LGRZG3V4TR.jpg  QZY3VNQSU6F1.jpg  ZXW3NB4KOPYD.jpg\n",
            "8P7T7XQTBPVL.jpg  I6HC41KF1WYC.jpg  R0VJDLJZ5D2Q.jpg  ZXWNI4MNM27X.jpg\n",
            "8P98MWJ2LN5X.jpg  I7VGJ0Q5OPH4.jpg  R0YPS51MONR1.jpg  ZYO6M4PRA6O5.jpg\n",
            "8ROWUSK8GZF9.jpg  I9TSPSFPLZ06.jpg  R10GVSEZ8LWJ.jpg  ZZ9QRQUF0L7B.jpg\n",
            "8S5DDEYRPHSH.jpg  IA2HT6ZZ1ATB.jpg  R15IFZNFLXUG.jpg  ZZSIXZ9IDJ32.jpg\n",
            "8TN5CBJZUEWL.jpg  IBBPD2I0TH03.jpg  R1A1IB1SI6S1.jpg\n",
            "8UF2GO5TMMHW.jpg  IDTNNGZT2PL1.jpg  R1WE7NR46TZ8.jpg\n",
            "8UO9T66O06Y1.jpg  IE6CK4X46QA3.jpg  R2W1WGED7VA9.jpg\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Images/goldfish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NgPp5Xgxcqd"
      },
      "source": [
        "/content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Images/goldfish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r96ORlaRyDoh"
      },
      "source": [
        "##Convert Images into TFrecords format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlP0W3AvyLfz",
        "outputId": "c686e94e-f74b-4156-b837-c12b591357e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: --dest folder must be empty\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan2-ada-pytorch/dataset_tool.py --source=/content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Images/goldfish --dest=/content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Dataset/00001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnxZJjNnUZ6S"
      },
      "source": [
        "##Training StyleGAN2-ADA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW1hiX_T5zft",
        "outputId": "02c56adb-4c2a-4dfa-d85e-6e5ea9304975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1509,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": 0.05,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1\n",
            "  },\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00000-00001-auto1-blit\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00000-00001-auto1-blit\n",
            "Training data:      /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   1509\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  1509\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 3m 01s       sec/tick 9.1     sec/kimg 569.06  maintenance 171.8  cpumem 4.68   gpumem 11.53  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "{\"results\": {\"fid50k_full\": 300.9755199168387}, \"metric\": \"fid50k_full\", \"total_time\": 714.0979869365692, \"total_time_str\": \"11m 54s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1661157359.9947035}\n",
            "tick 1     kimg 4.0      time 19m 47s      sec/tick 276.0   sec/kimg 68.99   maintenance 729.8  cpumem 4.81   gpumem 9.39   augment 0.005\n",
            "tick 2     kimg 8.0      time 24m 24s      sec/tick 276.9   sec/kimg 69.21   maintenance 0.1    cpumem 4.81   gpumem 4.83   augment 0.007\n",
            "tick 3     kimg 12.0     time 28m 59s      sec/tick 275.7   sec/kimg 68.92   maintenance 0.1    cpumem 4.81   gpumem 4.83   augment 0.011\n",
            "tick 4     kimg 16.0     time 33m 37s      sec/tick 277.2   sec/kimg 69.30   maintenance 0.1    cpumem 4.81   gpumem 4.83   augment 0.015\n",
            "tick 5     kimg 20.0     time 38m 14s      sec/tick 277.4   sec/kimg 69.34   maintenance 0.1    cpumem 4.81   gpumem 4.83   augment 0.019\n",
            "tick 6     kimg 24.0     time 42m 52s      sec/tick 277.2   sec/kimg 69.30   maintenance 0.1    cpumem 4.81   gpumem 4.83   augment 0.025\n",
            "tick 7     kimg 28.0     time 47m 29s      sec/tick 277.4   sec/kimg 69.35   maintenance 0.1    cpumem 4.81   gpumem 4.84   augment 0.031\n",
            "tick 8     kimg 32.0     time 52m 07s      sec/tick 277.4   sec/kimg 69.35   maintenance 0.1    cpumem 4.81   gpumem 4.83   augment 0.038\n",
            "tick 9     kimg 36.0     time 56m 43s      sec/tick 276.5   sec/kimg 69.12   maintenance 0.2    cpumem 4.81   gpumem 4.83   augment 0.045\n",
            "tick 10    kimg 40.0     time 1h 01m 21s   sec/tick 277.6   sec/kimg 69.41   maintenance 0.1    cpumem 4.81   gpumem 4.84   augment 0.051\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 264.1413783980987}, \"metric\": \"fid50k_full\", \"total_time\": 615.4573602676392, \"total_time_str\": \"10m 15s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1661160760.8471537}\n",
            "tick 11    kimg 44.0     time 1h 16m 29s   sec/tick 277.3   sec/kimg 69.33   maintenance 630.3  cpumem 4.95   gpumem 4.84   augment 0.057\n",
            "tick 12    kimg 48.0     time 1h 21m 07s   sec/tick 277.8   sec/kimg 69.46   maintenance 0.1    cpumem 4.95   gpumem 4.84   augment 0.062\n",
            "tick 13    kimg 52.0     time 1h 25m 44s   sec/tick 277.5   sec/kimg 69.37   maintenance 0.1    cpumem 4.95   gpumem 4.84   augment 0.065\n",
            "tick 14    kimg 56.0     time 1h 30m 22s   sec/tick 277.7   sec/kimg 69.42   maintenance 0.2    cpumem 4.95   gpumem 4.84   augment 0.070\n",
            "tick 15    kimg 60.0     time 1h 35m 00s   sec/tick 277.7   sec/kimg 69.42   maintenance 0.1    cpumem 4.95   gpumem 4.84   augment 0.076\n",
            "tick 16    kimg 64.0     time 1h 39m 38s   sec/tick 278.2   sec/kimg 69.56   maintenance 0.2    cpumem 4.95   gpumem 4.84   augment 0.082\n",
            "tick 17    kimg 68.0     time 1h 44m 16s   sec/tick 277.2   sec/kimg 69.30   maintenance 0.2    cpumem 4.95   gpumem 4.84   augment 0.086\n",
            "tick 18    kimg 72.0     time 1h 48m 54s   sec/tick 278.2   sec/kimg 69.54   maintenance 0.1    cpumem 4.95   gpumem 4.84   augment 0.092\n",
            "tick 19    kimg 76.0     time 1h 53m 32s   sec/tick 277.4   sec/kimg 69.35   maintenance 0.1    cpumem 4.95   gpumem 4.84   augment 0.097\n",
            "tick 20    kimg 80.0     time 1h 58m 10s   sec/tick 278.4   sec/kimg 69.61   maintenance 0.2    cpumem 4.95   gpumem 4.84   augment 0.103\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 274.78639654249264}, \"metric\": \"fid50k_full\", \"total_time\": 616.4015140533447, \"total_time_str\": \"10m 16s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000080.pkl\", \"timestamp\": 1661164175.5083904}\n",
            "tick 21    kimg 84.0     time 2h 13m 25s   sec/tick 278.4   sec/kimg 69.60   maintenance 635.9  cpumem 5.36   gpumem 4.84   augment 0.109\n",
            "tick 22    kimg 88.0     time 2h 18m 03s   sec/tick 277.9   sec/kimg 69.48   maintenance 0.1    cpumem 5.36   gpumem 4.84   augment 0.115\n",
            "tick 23    kimg 92.0     time 2h 22m 41s   sec/tick 278.2   sec/kimg 69.56   maintenance 0.1    cpumem 5.36   gpumem 4.84   augment 0.120\n",
            "tick 24    kimg 96.0     time 2h 27m 19s   sec/tick 278.3   sec/kimg 69.57   maintenance 0.1    cpumem 5.36   gpumem 4.84   augment 0.126\n",
            "tick 25    kimg 100.0    time 2h 31m 57s   sec/tick 277.9   sec/kimg 69.48   maintenance 0.2    cpumem 5.36   gpumem 4.84   augment 0.131\n",
            "tick 26    kimg 104.0    time 2h 36m 36s   sec/tick 278.6   sec/kimg 69.66   maintenance 0.1    cpumem 5.36   gpumem 4.84   augment 0.136\n",
            "tick 27    kimg 108.0    time 2h 41m 14s   sec/tick 277.5   sec/kimg 69.39   maintenance 0.1    cpumem 5.36   gpumem 4.84   augment 0.142\n",
            "tick 28    kimg 112.0    time 2h 45m 53s   sec/tick 278.6   sec/kimg 69.65   maintenance 0.2    cpumem 5.36   gpumem 4.84   augment 0.147\n",
            "tick 29    kimg 116.0    time 2h 50m 31s   sec/tick 278.1   sec/kimg 69.51   maintenance 0.1    cpumem 5.36   gpumem 4.84   augment 0.152\n",
            "tick 30    kimg 120.0    time 2h 55m 09s   sec/tick 278.1   sec/kimg 69.52   maintenance 0.2    cpumem 5.36   gpumem 4.84   augment 0.158\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 260.97667691457485}, \"metric\": \"fid50k_full\", \"total_time\": 616.7765955924988, \"total_time_str\": \"10m 17s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000120.pkl\", \"timestamp\": 1661167595.273549}\n",
            "tick 31    kimg 124.0    time 3h 10m 25s   sec/tick 278.7   sec/kimg 69.67   maintenance 636.7  cpumem 5.35   gpumem 4.84   augment 0.164\n",
            "tick 32    kimg 128.0    time 3h 15m 03s   sec/tick 278.5   sec/kimg 69.64   maintenance 0.2    cpumem 5.35   gpumem 4.84   augment 0.170\n",
            "tick 33    kimg 132.0    time 3h 19m 41s   sec/tick 277.8   sec/kimg 69.45   maintenance 0.2    cpumem 5.35   gpumem 4.84   augment 0.176\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "\n",
        "\n",
        "!python /content/stylegan2-ada-pytorch/train.py \\\n",
        "--snap=10 \\\n",
        "--augpipe=blit \\\n",
        "--data /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Dataset/00001 \\\n",
        "--outdir /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq1UVeMNjr9j"
      },
      "source": [
        "##Resume Training for StyleGAN2-ADA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_XqDvbkjrYC",
        "outputId": "b869b7fa-cd07-431f-fab3-f94b8bfa8af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1509,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00000-00001-auto1-blit/network-snapshot-000120.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom\n",
            "Training data:      /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   1509\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  1509\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00000-00001-auto1-blit/network-snapshot-000120.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 3m 07s       sec/tick 9.0     sec/kimg 562.58  maintenance 177.7  cpumem 5.06   gpumem 11.53  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "{\"results\": {\"fid50k_full\": 261.4613600958325}, \"metric\": \"fid50k_full\", \"total_time\": 719.4199092388153, \"total_time_str\": \"11m 59s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1661414051.9418488}\n",
            "tick 1     kimg 4.0      time 20m 14s      sec/tick 287.3   sec/kimg 71.82   maintenance 739.8  cpumem 5.21   gpumem 9.39   augment 0.031\n",
            "tick 2     kimg 8.0      time 25m 02s      sec/tick 288.1   sec/kimg 72.02   maintenance 0.2    cpumem 5.21   gpumem 4.83   augment 0.062\n",
            "tick 3     kimg 12.0     time 29m 49s      sec/tick 287.3   sec/kimg 71.83   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.090\n",
            "tick 4     kimg 16.0     time 34m 38s      sec/tick 288.6   sec/kimg 72.15   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.114\n",
            "tick 5     kimg 20.0     time 39m 26s      sec/tick 288.0   sec/kimg 71.99   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.142\n",
            "tick 6     kimg 24.0     time 44m 14s      sec/tick 287.9   sec/kimg 71.97   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.163\n",
            "tick 7     kimg 28.0     time 49m 03s      sec/tick 288.2   sec/kimg 72.06   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.193\n",
            "tick 8     kimg 32.0     time 53m 51s      sec/tick 288.6   sec/kimg 72.15   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.219\n",
            "tick 9     kimg 36.0     time 58m 40s      sec/tick 287.9   sec/kimg 71.98   maintenance 0.2    cpumem 5.21   gpumem 4.85   augment 0.244\n",
            "tick 10    kimg 40.0     time 1h 03m 29s   sec/tick 288.8   sec/kimg 72.21   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.271\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 256.92697544608745}, \"metric\": \"fid50k_full\", \"total_time\": 630.5213961601257, \"total_time_str\": \"10m 31s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1661417585.7343054}\n",
            "tick 11    kimg 44.0     time 1h 19m 09s   sec/tick 288.4   sec/kimg 72.09   maintenance 651.7  cpumem 5.57   gpumem 4.84   augment 0.292\n",
            "tick 12    kimg 48.0     time 1h 23m 58s   sec/tick 288.8   sec/kimg 72.19   maintenance 0.2    cpumem 5.57   gpumem 4.84   augment 0.312\n",
            "tick 13    kimg 52.0     time 1h 28m 46s   sec/tick 288.4   sec/kimg 72.11   maintenance 0.1    cpumem 5.57   gpumem 4.85   augment 0.329\n",
            "tick 14    kimg 56.0     time 1h 33m 35s   sec/tick 288.4   sec/kimg 72.10   maintenance 0.2    cpumem 5.57   gpumem 4.84   augment 0.360\n",
            "tick 15    kimg 60.0     time 1h 38m 23s   sec/tick 288.2   sec/kimg 72.06   maintenance 0.1    cpumem 5.57   gpumem 4.84   augment 0.378\n",
            "tick 16    kimg 64.0     time 1h 43m 13s   sec/tick 289.4   sec/kimg 72.34   maintenance 0.2    cpumem 5.57   gpumem 4.84   augment 0.394\n",
            "tick 17    kimg 68.0     time 1h 48m 01s   sec/tick 288.3   sec/kimg 72.07   maintenance 0.2    cpumem 5.57   gpumem 4.85   augment 0.410\n",
            "tick 18    kimg 72.0     time 1h 52m 50s   sec/tick 289.0   sec/kimg 72.25   maintenance 0.2    cpumem 5.57   gpumem 4.84   augment 0.431\n",
            "tick 19    kimg 76.0     time 1h 57m 39s   sec/tick 288.4   sec/kimg 72.10   maintenance 0.1    cpumem 5.57   gpumem 4.84   augment 0.448\n",
            "tick 20    kimg 80.0     time 2h 02m 28s   sec/tick 289.1   sec/kimg 72.28   maintenance 0.2    cpumem 5.57   gpumem 4.84   augment 0.460\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 199.27729265059048}, \"metric\": \"fid50k_full\", \"total_time\": 630.0553071498871, \"total_time_str\": \"10m 30s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000080.pkl\", \"timestamp\": 1661421123.559271}\n",
            "tick 21    kimg 84.0     time 2h 18m 07s   sec/tick 289.1   sec/kimg 72.27   maintenance 650.0  cpumem 5.47   gpumem 4.85   augment 0.480\n",
            "tick 22    kimg 88.0     time 2h 22m 56s   sec/tick 288.5   sec/kimg 72.13   maintenance 0.2    cpumem 5.47   gpumem 4.84   augment 0.495\n",
            "tick 23    kimg 92.0     time 2h 27m 45s   sec/tick 288.6   sec/kimg 72.15   maintenance 0.1    cpumem 5.47   gpumem 4.84   augment 0.502\n",
            "tick 24    kimg 96.0     time 2h 32m 34s   sec/tick 289.1   sec/kimg 72.27   maintenance 0.2    cpumem 5.47   gpumem 4.84   augment 0.509\n",
            "tick 25    kimg 100.0    time 2h 37m 22s   sec/tick 287.8   sec/kimg 71.96   maintenance 0.2    cpumem 5.47   gpumem 4.84   augment 0.518\n",
            "tick 26    kimg 104.0    time 2h 42m 11s   sec/tick 289.2   sec/kimg 72.29   maintenance 0.2    cpumem 5.47   gpumem 4.85   augment 0.524\n",
            "tick 27    kimg 108.0    time 2h 46m 59s   sec/tick 287.9   sec/kimg 71.98   maintenance 0.1    cpumem 5.47   gpumem 4.84   augment 0.531\n",
            "tick 28    kimg 112.0    time 2h 51m 48s   sec/tick 289.0   sec/kimg 72.24   maintenance 0.2    cpumem 5.47   gpumem 4.85   augment 0.531\n",
            "tick 29    kimg 116.0    time 2h 56m 37s   sec/tick 288.1   sec/kimg 72.02   maintenance 0.1    cpumem 5.47   gpumem 4.85   augment 0.536\n",
            "tick 30    kimg 120.0    time 3h 01m 25s   sec/tick 288.7   sec/kimg 72.16   maintenance 0.2    cpumem 5.47   gpumem 4.84   augment 0.547\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 148.78997492373938}, \"metric\": \"fid50k_full\", \"total_time\": 629.8807833194733, \"total_time_str\": \"10m 30s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000120.pkl\", \"timestamp\": 1661424661.2213197}\n",
            "tick 31    kimg 124.0    time 3h 17m 04s   sec/tick 288.5   sec/kimg 72.12   maintenance 650.4  cpumem 5.08   gpumem 4.84   augment 0.561\n",
            "tick 32    kimg 128.0    time 3h 21m 53s   sec/tick 288.8   sec/kimg 72.19   maintenance 0.2    cpumem 5.08   gpumem 4.84   augment 0.571\n",
            "tick 33    kimg 132.0    time 3h 26m 42s   sec/tick 288.5   sec/kimg 72.12   maintenance 0.2    cpumem 5.08   gpumem 4.85   augment 0.576\n",
            "tick 34    kimg 136.0    time 3h 31m 31s   sec/tick 289.4   sec/kimg 72.34   maintenance 0.2    cpumem 5.08   gpumem 4.85   augment 0.586\n",
            "tick 35    kimg 140.0    time 3h 36m 20s   sec/tick 288.8   sec/kimg 72.21   maintenance 0.2    cpumem 5.08   gpumem 4.85   augment 0.591\n",
            "tick 36    kimg 144.0    time 3h 41m 10s   sec/tick 289.2   sec/kimg 72.31   maintenance 0.2    cpumem 5.08   gpumem 4.85   augment 0.600\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan2-ada-pytorch/train.py \\\n",
        "--snap=10 \\\n",
        "--augpipe=blit \\\n",
        "--data /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Dataset/00001 \\\n",
        "--outdir /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments \\\n",
        "--resume /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments/00000-00001-auto1-blit/network-snapshot-000120.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SABn4RGVhltK",
        "outputId": "bf014bfc-2724-4fa3-9750-228b30edd5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1509,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00000-00001-auto1-blit/network-snapshot-000120.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00002-00001-auto1-blit-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00002-00001-auto1-blit-resumecustom\n",
            "Training data:      /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   1509\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  1509\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00000-00001-auto1-blit/network-snapshot-000120.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 57s          sec/tick 9.1     sec/kimg 566.58  maintenance 48.3   cpumem 5.00   gpumem 11.53  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 261.46357748541305}, \"metric\": \"fid50k_full\", \"total_time\": 626.380410194397, \"total_time_str\": \"10m 26s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1661427428.7542324}\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan2-ada-pytorch/train.py \\\n",
        "--snap=10 \\\n",
        "--augpipe=blit \\\n",
        "--data /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Dataset/00001 \\\n",
        "--outdir /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments \\\n",
        "--resume /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments/00000-00001-auto1-blit/network-snapshot-000120.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZpTNJxAzkON",
        "outputId": "dd9e794f-abb9-4f18-f6d7-f5e0faf7afea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1509,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00004-00001-auto1-blit-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00004-00001-auto1-blit-resumecustom\n",
            "Training data:      /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   1509\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  1509\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 56s          sec/tick 9.0     sec/kimg 561.88  maintenance 47.0   cpumem 5.08   gpumem 11.53  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 149.18527880033875}, \"metric\": \"fid50k_full\", \"total_time\": 634.3343443870544, \"total_time_str\": \"10m 34s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1661431392.2333837}\n",
            "tick 1     kimg 4.0      time 16m 33s      sec/tick 282.4   sec/kimg 70.59   maintenance 654.4  cpumem 5.11   gpumem 9.39   augment 0.035\n",
            "tick 2     kimg 8.0      time 21m 16s      sec/tick 283.4   sec/kimg 70.85   maintenance 0.1    cpumem 5.11   gpumem 4.84   augment 0.067\n",
            "tick 3     kimg 12.0     time 25m 59s      sec/tick 282.2   sec/kimg 70.56   maintenance 0.1    cpumem 5.11   gpumem 4.84   augment 0.097\n",
            "tick 4     kimg 16.0     time 30m 42s      sec/tick 283.3   sec/kimg 70.83   maintenance 0.1    cpumem 5.11   gpumem 4.84   augment 0.123\n",
            "tick 5     kimg 20.0     time 35m 26s      sec/tick 283.2   sec/kimg 70.81   maintenance 0.1    cpumem 5.11   gpumem 4.84   augment 0.148\n",
            "tick 6     kimg 24.0     time 40m 09s      sec/tick 283.5   sec/kimg 70.87   maintenance 0.1    cpumem 5.11   gpumem 4.84   augment 0.175\n",
            "tick 7     kimg 28.0     time 44m 53s      sec/tick 283.3   sec/kimg 70.83   maintenance 0.1    cpumem 5.11   gpumem 4.84   augment 0.200\n",
            "tick 8     kimg 32.0     time 49m 36s      sec/tick 283.6   sec/kimg 70.90   maintenance 0.1    cpumem 5.11   gpumem 4.84   augment 0.219\n",
            "tick 9     kimg 36.0     time 54m 19s      sec/tick 282.5   sec/kimg 70.64   maintenance 0.2    cpumem 5.11   gpumem 4.84   augment 0.243\n",
            "tick 10    kimg 40.0     time 59m 03s      sec/tick 283.6   sec/kimg 70.89   maintenance 0.1    cpumem 5.11   gpumem 4.84   augment 0.263\n",
            "Evaluating metrics...\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan2-ada-pytorch/train.py \\\n",
        "--snap=10 \\\n",
        "--augpipe=blit \\\n",
        "--data /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Dataset/00001 \\\n",
        "--outdir /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments \\\n",
        "--resume /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29LmI5-2aKKz"
      },
      "outputs": [],
      "source": [
        "!python /content/stylegan2-ada-pytorch/train.py \\\n",
        "--snap=10 \\\n",
        "--augpipe=blit \\\n",
        "--data /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Dataset/00001 \\\n",
        "--outdir /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments \\\n",
        "--resume /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeanT-sEQbqK",
        "outputId": "52cb4d36-d502-4981-df98-822034705f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1509,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00005-00001-auto1-blit-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00005-00001-auto1-blit-resumecustom\n",
            "Training data:      /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   1509\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  1509\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 3m 20s       sec/tick 9.4     sec/kimg 586.88  maintenance 190.5  cpumem 5.08   gpumem 11.53  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "{\"results\": {\"fid50k_full\": 149.18135081330976}, \"metric\": \"fid50k_full\", \"total_time\": 754.4798576831818, \"total_time_str\": \"12m 34s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1661533255.158369}\n",
            "tick 1     kimg 4.0      time 21m 10s      sec/tick 295.4   sec/kimg 73.84   maintenance 774.4  cpumem 5.21   gpumem 9.39   augment 0.029\n",
            "tick 2     kimg 8.0      time 26m 06s      sec/tick 295.9   sec/kimg 73.98   maintenance 0.2    cpumem 5.21   gpumem 4.83   augment 0.054\n",
            "tick 3     kimg 12.0     time 31m 01s      sec/tick 294.9   sec/kimg 73.74   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.086\n",
            "tick 4     kimg 16.0     time 35m 57s      sec/tick 295.8   sec/kimg 73.94   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.118\n",
            "tick 5     kimg 20.0     time 40m 53s      sec/tick 296.2   sec/kimg 74.04   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.147\n",
            "tick 6     kimg 24.0     time 45m 50s      sec/tick 296.2   sec/kimg 74.05   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.175\n",
            "tick 7     kimg 28.0     time 50m 45s      sec/tick 295.4   sec/kimg 73.86   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.204\n",
            "tick 8     kimg 32.0     time 55m 42s      sec/tick 296.4   sec/kimg 74.09   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.228\n",
            "tick 9     kimg 36.0     time 1h 00m 37s   sec/tick 295.3   sec/kimg 73.83   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.252\n",
            "tick 10    kimg 40.0     time 1h 05m 34s   sec/tick 296.5   sec/kimg 74.12   maintenance 0.2    cpumem 5.21   gpumem 4.84   augment 0.273\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 154.19071726717138}, \"metric\": \"fid50k_full\", \"total_time\": 652.4862897396088, \"total_time_str\": \"10m 52s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1661536887.2763317}\n",
            "tick 11    kimg 44.0     time 1h 21m 42s   sec/tick 296.0   sec/kimg 73.99   maintenance 672.8  cpumem 5.57   gpumem 4.85   augment 0.291\n",
            "tick 12    kimg 48.0     time 1h 26m 40s   sec/tick 297.0   sec/kimg 74.24   maintenance 0.2    cpumem 5.57   gpumem 4.85   augment 0.313\n",
            "tick 13    kimg 52.0     time 1h 31m 36s   sec/tick 296.1   sec/kimg 74.02   maintenance 0.2    cpumem 5.57   gpumem 4.84   augment 0.331\n",
            "tick 14    kimg 56.0     time 1h 36m 32s   sec/tick 296.2   sec/kimg 74.05   maintenance 0.2    cpumem 5.57   gpumem 4.85   augment 0.352\n",
            "tick 15    kimg 60.0     time 1h 41m 29s   sec/tick 296.6   sec/kimg 74.16   maintenance 0.2    cpumem 5.57   gpumem 4.85   augment 0.376\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan2-ada-pytorch/train.py \\\n",
        "--snap=10 \\\n",
        "--augpipe=blit \\\n",
        "--data /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Dataset/00001 \\\n",
        "--outdir /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments \\\n",
        "--resume /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments/00001-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R0TXKWPaOX6",
        "outputId": "2657227a-1a45-48fb-d698-9735bed064b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1509,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00016-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00017-00001-auto1-blit-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00017-00001-auto1-blit-resumecustom\n",
            "Training data:      /content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Dataset/00001\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   1509\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  1509\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/Data_DURF Project/GAN2-ADA/Experiments/00016-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 2m 30s       sec/tick 9.0     sec/kimg 564.75  maintenance 140.5  cpumem 5.09   gpumem 11.53  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "{\"results\": {\"fid50k_full\": 42.986011761092016}, \"metric\": \"fid50k_full\", \"total_time\": 693.08442735672, \"total_time_str\": \"11m 33s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1665384885.6030607}\n",
            "tick 1     kimg 4.0      time 19m 14s      sec/tick 292.1   sec/kimg 73.01   maintenance 712.8  cpumem 5.19   gpumem 9.39   augment 0.037\n",
            "tick 2     kimg 8.0      time 24m 07s      sec/tick 292.8   sec/kimg 73.19   maintenance 0.2    cpumem 5.19   gpumem 4.84   augment 0.076\n",
            "tick 3     kimg 12.0     time 28m 59s      sec/tick 291.8   sec/kimg 72.95   maintenance 0.2    cpumem 5.19   gpumem 4.84   augment 0.113\n",
            "tick 4     kimg 16.0     time 33m 52s      sec/tick 292.7   sec/kimg 73.19   maintenance 0.2    cpumem 5.19   gpumem 4.84   augment 0.152\n",
            "tick 5     kimg 20.0     time 38m 45s      sec/tick 292.7   sec/kimg 73.18   maintenance 0.2    cpumem 5.19   gpumem 4.84   augment 0.191\n",
            "tick 6     kimg 24.0     time 43m 38s      sec/tick 293.1   sec/kimg 73.27   maintenance 0.2    cpumem 5.19   gpumem 4.84   augment 0.228\n",
            "tick 7     kimg 28.0     time 48m 31s      sec/tick 292.6   sec/kimg 73.16   maintenance 0.2    cpumem 5.19   gpumem 4.84   augment 0.267\n",
            "tick 8     kimg 32.0     time 53m 24s      sec/tick 293.2   sec/kimg 73.29   maintenance 0.2    cpumem 5.19   gpumem 4.84   augment 0.305\n",
            "tick 9     kimg 36.0     time 58m 17s      sec/tick 293.0   sec/kimg 73.24   maintenance 0.2    cpumem 5.19   gpumem 4.84   augment 0.342\n",
            "tick 10    kimg 40.0     time 1h 03m 11s   sec/tick 293.6   sec/kimg 73.40   maintenance 0.2    cpumem 5.19   gpumem 4.85   augment 0.381\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 52.71319148633164}, \"metric\": \"fid50k_full\", \"total_time\": 645.0463662147522, \"total_time_str\": \"10m 45s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1665388479.31624}\n",
            "tick 11    kimg 44.0     time 1h 19m 09s   sec/tick 293.0   sec/kimg 73.25   maintenance 664.8  cpumem 5.54   gpumem 4.85   augment 0.417\n",
            "tick 12    kimg 48.0     time 1h 24m 03s   sec/tick 293.6   sec/kimg 73.40   maintenance 0.2    cpumem 5.53   gpumem 4.85   augment 0.455\n",
            "tick 13    kimg 52.0     time 1h 28m 56s   sec/tick 293.1   sec/kimg 73.28   maintenance 0.2    cpumem 5.53   gpumem 4.84   augment 0.493\n",
            "tick 14    kimg 56.0     time 1h 33m 49s   sec/tick 293.0   sec/kimg 73.26   maintenance 0.2    cpumem 5.53   gpumem 4.85   augment 0.531\n",
            "tick 15    kimg 60.0     time 1h 38m 43s   sec/tick 293.8   sec/kimg 73.44   maintenance 0.2    cpumem 5.53   gpumem 4.85   augment 0.568\n",
            "tick 16    kimg 64.0     time 1h 43m 37s   sec/tick 294.2   sec/kimg 73.54   maintenance 0.2    cpumem 5.53   gpumem 4.85   augment 0.606\n",
            "tick 17    kimg 68.0     time 1h 48m 31s   sec/tick 293.0   sec/kimg 73.25   maintenance 0.2    cpumem 5.53   gpumem 4.85   augment 0.644\n",
            "tick 18    kimg 72.0     time 1h 53m 25s   sec/tick 293.8   sec/kimg 73.44   maintenance 0.2    cpumem 5.53   gpumem 4.85   augment 0.684\n",
            "tick 19    kimg 76.0     time 1h 58m 18s   sec/tick 293.1   sec/kimg 73.29   maintenance 0.2    cpumem 5.53   gpumem 4.85   augment 0.721\n",
            "tick 20    kimg 80.0     time 2h 03m 12s   sec/tick 294.5   sec/kimg 73.61   maintenance 0.2    cpumem 5.53   gpumem 4.85   augment 0.760\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 42.634897595244446}, \"metric\": \"fid50k_full\", \"total_time\": 643.9642915725708, \"total_time_str\": \"10m 44s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000080.pkl\", \"timestamp\": 1665392079.0586689}\n",
            "tick 21    kimg 84.0     time 2h 19m 10s   sec/tick 294.2   sec/kimg 73.56   maintenance 663.3  cpumem 5.39   gpumem 4.85   augment 0.796\n",
            "tick 22    kimg 88.0     time 2h 24m 04s   sec/tick 294.4   sec/kimg 73.59   maintenance 0.2    cpumem 5.39   gpumem 4.85   augment 0.833\n",
            "tick 23    kimg 92.0     time 2h 28m 59s   sec/tick 294.2   sec/kimg 73.55   maintenance 0.2    cpumem 5.39   gpumem 4.85   augment 0.868\n",
            "tick 24    kimg 96.0     time 2h 33m 54s   sec/tick 295.2   sec/kimg 73.79   maintenance 0.2    cpumem 5.39   gpumem 4.85   augment 0.903\n",
            "tick 25    kimg 100.0    time 2h 38m 48s   sec/tick 294.0   sec/kimg 73.50   maintenance 0.2    cpumem 5.38   gpumem 4.85   augment 0.938\n",
            "tick 26    kimg 104.0    time 2h 43m 43s   sec/tick 295.0   sec/kimg 73.74   maintenance 0.2    cpumem 5.38   gpumem 4.85   augment 0.973\n",
            "tick 27    kimg 108.0    time 2h 48m 37s   sec/tick 293.6   sec/kimg 73.40   maintenance 0.2    cpumem 5.37   gpumem 4.85   augment 1.011\n",
            "tick 28    kimg 112.0    time 2h 53m 32s   sec/tick 294.9   sec/kimg 73.73   maintenance 0.2    cpumem 5.36   gpumem 4.85   augment 1.046\n",
            "tick 29    kimg 116.0    time 2h 58m 27s   sec/tick 294.7   sec/kimg 73.66   maintenance 0.2    cpumem 5.36   gpumem 4.85   augment 1.082\n",
            "tick 30    kimg 120.0    time 3h 03m 22s   sec/tick 294.3   sec/kimg 73.58   maintenance 0.2    cpumem 5.36   gpumem 4.85   augment 1.119\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 44.75744057074449}, \"metric\": \"fid50k_full\", \"total_time\": 644.8009083271027, \"total_time_str\": \"10m 45s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000120.pkl\", \"timestamp\": 1665395689.4009643}\n",
            "tick 31    kimg 124.0    time 3h 19m 21s   sec/tick 294.7   sec/kimg 73.68   maintenance 664.5  cpumem 5.24   gpumem 4.85   augment 1.153\n",
            "tick 32    kimg 128.0    time 3h 24m 15s   sec/tick 294.5   sec/kimg 73.63   maintenance 0.2    cpumem 5.24   gpumem 4.85   augment 1.186\n",
            "tick 33    kimg 132.0    time 3h 29m 09s   sec/tick 293.7   sec/kimg 73.43   maintenance 0.2    cpumem 5.24   gpumem 4.85   augment 1.220\n",
            "tick 34    kimg 136.0    time 3h 34m 04s   sec/tick 294.7   sec/kimg 73.68   maintenance 0.2    cpumem 5.24   gpumem 4.85   augment 1.256\n",
            "tick 35    kimg 140.0    time 3h 38m 58s   sec/tick 294.0   sec/kimg 73.50   maintenance 0.2    cpumem 5.24   gpumem 4.85   augment 1.292\n",
            "tick 36    kimg 144.0    time 3h 43m 53s   sec/tick 294.8   sec/kimg 73.69   maintenance 0.2    cpumem 5.24   gpumem 4.85   augment 1.328\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan2-ada-pytorch/train.py \\\n",
        "--snap=10 \\\n",
        "--augpipe=blit \\\n",
        "--data /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Dataset/00001 \\\n",
        "--outdir /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments \\\n",
        "--resume /content/drive/MyDrive/Data_DURF\\ Project/GAN2-ADA/Experiments/00016-00001-auto1-blit-resumecustom/network-snapshot-000120.pkl"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYkabR4proiWf9eVTha76I",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}